{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/engineeringjoy/SynAnalyzer/blob/main/SynAnalyzer_ConvertImarisStatsFile.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JL5DR04zh4A8"
   },
   "source": [
    "# SynAnalyzer_1.0.ConvertImarisStatsFile_Local.ipynb\n",
    "Created by: JFranco | Created On: 5 AUG 2024 | Last Env: SynCounting | Last Run Date: 15 AUG 2024\n",
    "\n",
    "This Python notebook is first module in the Synapse Analyzer pipeline. The purpose of the notebook is to take Excel files that were generated by Imaris, containing the statistics of all surfaces, and convert them into a simplified format that can be used by SynAnalyzer.ijm. The default values that are extracted are:\n",
    "\n",
    "1. Surface ID as assigned by Imaris  \n",
    "2. XYZ Positions\n",
    "3. Volume for each surface\n",
    "\n",
    "To change the voxel dimension settings, open a raw image in ImageJ and then go to the Image menu and select \"Show Info.\" This information helps to ensure that thumbnails are generated at precisely the correct position to avoid ImageJ macro rounding errors.  \n",
    "\n",
    "This code requires that the .xls files are in the original format output by Imaris. If \"Spots\" were used in Imaris, rather than surfaces, the code relating to volume extraction will need to adjusted.\n",
    "\n",
    "Version Notes: This version has minor changes so that it runs locally in a SynAnalysis batch folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LFzBLF-lgrL9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                *** WHAT TO ANALYZE // WHERE TO GET/STORE **\n",
    "# Key identifiers\n",
    "batchID = 'Ntng1NIHL_2023'\n",
    "\n",
    "# Voxel dimensions for converting XYZs (in um)\n",
    "voxelWidth = 0.0248\n",
    "voxelHeight = 0.0248\n",
    "voxelDepth = 0.31\n",
    "\n",
    "# Threshold for volume of surfaces to include. Must be greater than zero!\n",
    "#   Volumes that are too small do not have a mean intensity and it will result in a runtime error\n",
    "volThresh = 0.1\n",
    "\n",
    "# Directories \n",
    "#   existing ones \n",
    "dirMain = '/Users/joyfranco/Dropbox (Partners HealthCare)/JF_Shared/Data/FromCollaborators/Copeland2024/'\n",
    "dirBA = dirMain+batchID+'/'\n",
    "dirData = dirBA+'ImarisStatsFiles/'\n",
    "\n",
    "#   ones that need to be made    \n",
    "dirSV = dirBA+'XYZCSVs/'        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#           *** INITIALIZE RUN SPECIFIC DIRECTORY ETC FOR STORING RESULTS **\n",
    "# Create directory for storing spreadsheetS and summary plotS for this run\n",
    "if not os.path.exists(dirSV): os.mkdir(dirSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u-NYHDaDiV5A",
    "outputId": "af000037-137c-42df-8bdf-d820a536c021"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WSS_022.H.T1.02.Zs.4C.XYZ.PreSyn.xls', 'WSS_022.B.T2.02.ZS.4C.XYZ.PreSyn.xls', 'WSS_022.J.T1.01.Zs.4C.XYZ.PreSyn.xls', 'WSS_022.H.T1.02.Zs.4C.XYZ.PostSyn.xls', 'WSS_022.J.T1.01.Zs.4C.XYZ.PostSyn.xls', 'WSS_022.E.T1.01.Zs.4C.XYZ.PostSyn.xls', 'WSS_022.G.T3.02.Zs.4C.XYZ.PreSyn.xls', 'WSS_022.E.T1.01.Zs.4C.XYZ.PreSyn.xls', 'WSS_022.F.T2.02.Zs.4C.XYZ.PostSyn.xls', 'WSS_022.G.T3.02.Zs.4C.XYZ.PostSyn.xls', 'WSS_022.F.T2.02.Zs.4C.XYZ.PreSyn.xls', 'WSS_022.B.T2.02.ZS.4C.XYZ.PostSyn.xls', 'WSS_022.C.T3.02.ZS.4C.XYZ.PostSyn.xls', 'WSS_022.C.T3.02.ZS.4C.XYZ.PreSyn.xls']\n"
     ]
    }
   ],
   "source": [
    "#           *** GENERATE A LIST OF FILES THAT WILL BE CONVERTED **\n",
    "# This list is based off the available Excel results. \n",
    "# Generate a list of all xls files added by the user\n",
    "os.chdir(dirData)\n",
    "files = glob.glob('*Syn.xls')\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0NOiEnO9jdKX"
   },
   "outputs": [],
   "source": [
    "# Iterate through the xls files, extract the relavent sheet, and reformat\n",
    "for file in files:\n",
    "    # Read in the sheets that correspond to each desired df\n",
    "    dfXYZ = pd.read_excel(file,skiprows=1, sheet_name='Position')\n",
    "    dfVol = pd.read_excel(file,skiprows=1, sheet_name='Volume')\n",
    "    dfIMO = pd.read_excel(file, sheet_name='Intensity Mean Ch=1 Img=1')\n",
    "    dfIMT = pd.read_excel(file,sheet_name='Intensity Mean Ch=2 Img=1')\n",
    "    dfIMTh = pd.read_excel(file,sheet_name='Intensity Mean Ch=3 Img=1')\n",
    "    dfIMF = pd.read_excel(file,sheet_name='Intensity Mean Ch=4 Img=1')\n",
    "    \n",
    "    # Reformat each df to make it a proper df rather than sheet\n",
    "    dfXYZ = dfXYZ.drop(columns=['Unit', 'Category', 'Collection', 'Time'])\n",
    "    dfXYZ.set_index('ID', inplace=True)\n",
    "    dfVol = dfVol.drop(columns=['Unit', 'Category','Time'])\n",
    "    dfVol.set_index('ID', inplace=True)\n",
    "    \n",
    "    #dfIMO = dfIMO.drop(columns=['Unit', 'Category', 'Channel','Image','Time'])\n",
    "    dfIMO.columns = dfIMO.iloc[0]\n",
    "    dfIMO.drop(dfIMO.head(1).index, inplace=True)\n",
    "    dfIMO.set_index('ID', inplace=True)\n",
    "    \n",
    "    #dfIMT = dfIMT.drop(columns=['Unit', 'Category', 'Channel','Image','Time'])\n",
    "    dfIMT.columns = dfIMT.iloc[0]\n",
    "    dfIMT.drop(dfIMT.head(1).index, inplace=True)\n",
    "    dfIMT.set_index('ID', inplace=True)\n",
    "    \n",
    "    #dfIMTh = dfIMTh.drop(columns=['Unit', 'Category', 'Channel','Image','Time'])\n",
    "    dfIMTh.columns = dfIMTh.iloc[0]\n",
    "    dfIMTh.drop(dfIMTh.head(1).index, inplace=True)\n",
    "    dfIMTh.set_index('ID', inplace=True)\n",
    "    \n",
    "    #dfIMF = dfIMF.drop(columns=['Unit', 'Category', 'Channel','Image','Time'])\n",
    "    dfIMF.columns = dfIMF.iloc[0]\n",
    "    dfIMF.drop(dfIMF.head(1).index, inplace=True)\n",
    "    dfIMF.set_index('ID', inplace=True)\n",
    "    \n",
    "    # Need to transfer the information about the volume over the XYZ df without\n",
    "    #. assumptions about df order\n",
    "    for id in list(dfXYZ.index.values):\n",
    "        # Get the volume associated with this ID from the volume df\n",
    "        vol = dfVol['Volume'][id]\n",
    "         \n",
    "\n",
    "        # Filter out any surfaces with volume below threshold\n",
    "        if (vol > volThresh):\n",
    "            dfXYZ.at[id, 'Volume_um3'] = vol\n",
    "            \n",
    "            # First convert position from XYZ in microns to XYZ in voxels\n",
    "            xPos = dfXYZ['Position X'][id]\n",
    "            yPos = dfXYZ['Position Y'][id]\n",
    "            zPos = dfXYZ['Position Z'][id]\n",
    "    \n",
    "            dfXYZ.at[id, 'Position X (voxels)'] = xPos/voxelWidth\n",
    "            dfXYZ.at[id, 'Position Y (voxels)'] = yPos/voxelHeight\n",
    "            dfXYZ.at[id, 'Position Z (voxels)'] = round(zPos/voxelDepth)\n",
    "            \n",
    "            \n",
    "    \n",
    "            # Get the ch1 mean intensity\n",
    "            dfXYZ.at[id, 'uIntCh_1'] = dfIMO['Intensity Mean'][id]\n",
    "            # Get the ch2 mean intensity\n",
    "            dfXYZ.at[id, 'uIntCh_2'] = dfIMT['Intensity Mean'][id]\n",
    "            # Get the ch3 mean intensity\n",
    "            dfXYZ.at[id, 'uIntCh_3'] = dfIMTh['Intensity Mean'][id]\n",
    "            # Get the ch4 mean intensity\n",
    "            dfXYZ.at[id, 'uIntCh_4'] = dfIMF['Intensity Mean'][id]\n",
    "        else:\n",
    "            dfXYZ.drop(id, inplace = True)\n",
    "\n",
    "    # Save the dataframe as a csv file    \n",
    "    dfXYZ.to_csv(dirSV+file.split('.x')[0]+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMCVtypA5HzYdKA3IoutRoM",
   "include_colab_link": true,
   "mount_file_id": "https://github.com/engineeringjoy/SynAnalyzer/blob/main/SynAnalyzer_ConvertImarisStatsFile.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
